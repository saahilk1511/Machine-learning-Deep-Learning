{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f326d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from tensorflow import keras\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9ed4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGradientNetwork(keras.Model):\n",
    "    def __init__(self, l1_dims=62, l2_dims=32):\n",
    "        super(PolicyGradientNetwork, self).__init__()\n",
    "        self.l1_dims = l1_dims\n",
    "        self.l2_dims = l2_dims\n",
    "\n",
    "        # input shape is equivalent to the shape of observation space\n",
    "        self.d1 = tf.keras.layers.Dense(self.l1_dims, activation='relu', input_shape=[8,])\n",
    "        self.d2 = tf.keras.layers.Dense(self.l2_dims, activation='relu')\n",
    "\n",
    "        # output layer is equivalent to the shape of action space, because network will provide the best possible policy which is best action in any given state.\n",
    "        self.o = tf.keras.layers.Dense(4, activation='softmax')\n",
    "\n",
    "    ## used for forward network and it will take the state of game as an input\n",
    "    def call(self, state):\n",
    "        value = self.d1(state)\n",
    "        value = self.d2(value)\n",
    "\n",
    "        o = self.o(value)\n",
    "\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103b7308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 15:58:33.374796: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-11 15:58:33.375026: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.003\n",
    "gamma = 0.95\n",
    "pgn = PolicyGradientNetwork()\n",
    "pgn.compile(optimizer=Adam(learning_rate=lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499326cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_action(observation):\n",
    "\n",
    "  # converting the observation to tensor, to pass in out Polic Gradient Network\n",
    "    state = tf.convert_to_tensor([observation], dtype=tf.float32)\n",
    "  \n",
    "  # it will return the probability of each 4 actions\n",
    "    probs = pgn(state)\n",
    "\n",
    "  # converting the probability to categorical variable\n",
    "    action_probs = tfp.distributions.Categorical(probs=probs)\n",
    "\n",
    "  # selecting the action\n",
    "    action = action_probs.sample()\n",
    "  \n",
    "  # action return from sampling will be a array of one element i.e., the best possible action\n",
    "    return action.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c25934cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(state_memory, action_memory, reward_memory, update_wts):\n",
    "    \n",
    "    actions = tf.convert_to_tensor(action_memory, dtype=tf.float32)\n",
    "    rewards = np.array(reward_memory)\n",
    "    \n",
    "    '''\n",
    "      It will take action memory, state memory and reward memory as an\n",
    "      input. These memory are build using random action for a random state, \n",
    "      and what is the reward for the action taken in given state.\n",
    "      The rewards, actions and state are saved in array, thenn passed as n input \n",
    "      parameter in this function. Using the random actions, random states and rewards,\n",
    "      our policy gradient network is going to find the best possible action for each \n",
    "      state, so that network can maximise the reward.\n",
    "    '''\n",
    "    \n",
    "\n",
    "  # calculating reward for all time till the end of game.\n",
    "    G = np.zeros_like(rewards)\n",
    "    for t in range(len(rewards)):\n",
    "        G_sum = 0\n",
    "        discount = 1\n",
    "        for k in range(t, len(rewards)):\n",
    "            G_sum += rewards[k] * discount\n",
    "            discount *= gamma\n",
    "            G[t] = G_sum\n",
    "\n",
    "  # Gradient tape is added in tensorflow2.0, which will increase the computation speed.    \n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 0\n",
    "\n",
    "    # using the given state memory for an episode, network is trying to minimize \n",
    "    #the loss and maximize the reward\n",
    "        for idx, (g, state) in enumerate(zip(G, state_memory)):\n",
    "        \n",
    "\n",
    "      # converting the state/observation to tensor so that we can pass into out network.\n",
    "            state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
    "      \n",
    "      # predicting the probability for each action\n",
    "            probs = pgn(state)\n",
    "      \n",
    "            action_probs = tfp.distributions.Categorical(probs=probs)\n",
    "      \n",
    "            log_prob = action_probs.log_prob(actions[idx])\n",
    "      \n",
    "      # minus sign means we are trying to maximize the reward, becasue gradient descent will bydefault try to minimize it.\n",
    "            loss += -g * tf.squeeze(log_prob)\n",
    "\n",
    "  # calcuating the gradient for losses over each action taken in given state during single episode.\n",
    "    gradient = tape.gradient(loss, pgn.trainable_variables)\n",
    "  \n",
    "    pgn.optimizer.apply_gradients(zip(gradient, pgn.trainable_variables))\n",
    "\n",
    "    pgn.save(\"best_model\")\n",
    "  \n",
    "    if update_wts:\n",
    "        # updatung wts\n",
    "        print(\"Updating Wts\")\n",
    "        wts = np.array(pgn.get_weights())\n",
    "        pgn.set_weights(wts + 0.001)\n",
    "  \n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e9c54cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 16:02:49.703772: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  1 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  2 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  3 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  4 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  5 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  6 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  7 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  8 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  9 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  10 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  11 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  12 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  13 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "Updating Wts\n",
      "episode:  14 score: -100.0 average score -100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/4psym4l52gzbg9swfsnj2vzm0000gn/T/ipykernel_6067/2937820526.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  wts = np.array(pgn.get_weights())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  15 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  16 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  17 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  18 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  19 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  20 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  21 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  22 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  23 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  24 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  25 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  26 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  27 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  28 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  29 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  30 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  31 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  32 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  33 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  34 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  35 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  36 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  37 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  38 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  39 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  40 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  41 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  42 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  43 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  44 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  45 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  46 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  47 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  48 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  49 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  50 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  51 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  52 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  53 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  54 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  55 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  56 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  57 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  58 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  59 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  60 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  61 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  62 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  63 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  64 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  65 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  66 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  67 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  68 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  69 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  70 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  71 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  72 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  73 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  74 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  75 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  76 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  77 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  78 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  79 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  80 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  81 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  82 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  83 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  84 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  85 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  86 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  87 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  88 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  89 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  90 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  91 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  92 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  93 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  94 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  95 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  96 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  97 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  98 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  99 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  100 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  101 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  102 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  103 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  104 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  105 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  106 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  107 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  108 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  109 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  110 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  111 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  112 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  113 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  114 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  115 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  116 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  117 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  118 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  119 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  120 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  121 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  122 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  123 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  124 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  125 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  126 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  127 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  128 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  129 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  130 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  131 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  132 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  133 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  134 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  135 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  136 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  137 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  138 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  139 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  140 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  141 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  142 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  143 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  144 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  145 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  146 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  147 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  148 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  149 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  150 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  151 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  152 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  153 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  154 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  155 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  156 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  157 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  158 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  159 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  160 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  161 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  162 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  163 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  164 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  165 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  166 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  167 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  168 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  169 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  170 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  171 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  172 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  173 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  174 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  175 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  176 score: -100.0 average score -100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  177 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  178 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  179 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  180 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  181 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  182 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  183 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  184 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  185 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  186 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  187 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  188 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  189 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  190 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  191 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  192 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  193 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  194 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  195 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  196 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  197 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  198 score: -100.0 average score -100.0\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "episode:  199 score: -100.0 average score -100.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    env = gym.make(\"LunarLander-v2\")\n",
    "    \n",
    "    score_history = []\n",
    "\n",
    "    n_games = 200\n",
    "\n",
    "\n",
    "    # looping over each episode and each episode consist of 100 rounds\n",
    "    for i in range(n_games):\n",
    "        done = False\n",
    "        score = 0\n",
    "        update_wts = False\n",
    "\n",
    "      # it will contains the state sampled in each round of a given episodes\n",
    "        state_memory = []\n",
    "\n",
    "      # it will contains the action samples for a given state in each round of a given episodes\n",
    "        action_memory = []\n",
    "\n",
    "      # it will contains the reward for a given action and state in each round of a given episodes.\n",
    "        reward_memory = []\n",
    "\n",
    "      # resetting the environment on each episode, so that we start with fresh slate\n",
    "        observation = env.reset()\n",
    "\n",
    "        j = 0\n",
    "      # looping over for max of 1000 round in episode\n",
    "        while j < 1000 and not done:\n",
    "\n",
    "        # calling take action function get one random action\n",
    "            action = take_action(observation)\n",
    "\n",
    "        # perfoming the action in a given state of a game\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "\n",
    "        # saving the state, action and reward in an array, so that we can use the states, memory and reward from each episode to learn the best policy\n",
    "            state_memory.append(observation)\n",
    "            action_memory.append(action)\n",
    "            reward_memory.append(reward)\n",
    "\n",
    "            observation = observation_\n",
    "\n",
    "        # cummalating the rewards\n",
    "        score += reward\n",
    "        score_history.append(score)\n",
    "        j+=1\n",
    "        if i == 14:\n",
    "            update_wts = True\n",
    "\n",
    "      # learning the best possible action for a particular episode\n",
    "        learn(state_memory, action_memory, reward_memory, update_wts)\n",
    "        avg_score = np.mean(score_history[-100:])\n",
    "        print('episode: ', i,'score: %.1f' % score,'average score %.1f' % avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8964f87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tfd)",
   "language": "python",
   "name": "tfd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
